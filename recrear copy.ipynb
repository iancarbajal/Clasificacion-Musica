{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import jsonlines\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 22050\n",
    "TOTAL_SAMPLES = 29 * sr\n",
    "\n",
    "NUM_SLICES = 10\n",
    "SAMPLES_PER_SLICE = int(TOTAL_SAMPLES / NUM_SLICES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_data_MFCC(source_path, tfrecord_path):\n",
    "\n",
    "    def _bytes_feature(value):\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[tf.io.serialize_tensor(value).numpy()]))\n",
    "\n",
    "    def _int64_feature(value):\n",
    "        return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "    def serialize_example(mfcc, label):\n",
    "        feature = {\n",
    "            'mfcc': _bytes_feature(tf.convert_to_tensor(mfcc, dtype=tf.float32)),\n",
    "            'label': _int64_feature(label)\n",
    "        }\n",
    "        example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "        return example_proto.SerializeToString()\n",
    "\n",
    "    with tf.io.TFRecordWriter(tfrecord_path) as writer:\n",
    "\n",
    "        # Browse each file, slice it, and generate the 128-band MFCC for each slice.\n",
    "        for i, (dirpath, dirname, filenames) in enumerate(os.walk(source_path)):\n",
    "            for file in filenames:\n",
    "                # Exclude a corrupted wav file that makes everything crash.\n",
    "                if os.path.join(dirpath, file) != 'genres_original/jazz/jazz.00054.wav':\n",
    "                    song, sr = librosa.load(os.path.join(dirpath, file), duration=29)\n",
    "                    for s in range(NUM_SLICES):\n",
    "                        start_sample = SAMPLES_PER_SLICE * s\n",
    "                        end_sample = start_sample + SAMPLES_PER_SLICE\n",
    "\n",
    "                        slice_song = song[start_sample:end_sample]\n",
    "\n",
    "                        # Compute MFCC\n",
    "                        mfcc = librosa.feature.mfcc(y=slice_song, sr=sr, n_mfcc=128)\n",
    "                        mfcc = mfcc.T\n",
    "\n",
    "                        # Serialize example and write to TFRecord file\n",
    "                        label = i - 1  # Adjust label indexing if necessary\n",
    "                        example = serialize_example(mfcc, label)\n",
    "                        writer.write(example)\n",
    "                else:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_STFT(source_path, tfrecord_path):\n",
    "    \n",
    "    def _bytes_feature(value):\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[tf.io.serialize_tensor(value).numpy()]))\n",
    "\n",
    "    def _int64_feature(value):\n",
    "        return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "    def serialize_example(stft, label):\n",
    "        feature = {\n",
    "            'stft': _bytes_feature(stft),\n",
    "            'label': _int64_feature(label)\n",
    "        }\n",
    "        example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "        return example_proto.SerializeToString()\n",
    "\n",
    "\n",
    "    with tf.io.TFRecordWriter(tfrecord_path) as writer:\n",
    "\n",
    "        # Browse each file, slice it, and generate the STFT for each slice.\n",
    "        for i, (dirpath, dirname, filenames) in enumerate(os.walk(source_path)):\n",
    "            for file in filenames:\n",
    "                # Exclude a corrupted wav file that makes everything crash.\n",
    "                if os.path.join(dirpath, file) != 'genres_original/jazz/jazz.00054.wav':\n",
    "                    song, sr = librosa.load(os.path.join(dirpath, file), duration=29)\n",
    "                    for s in range(NUM_SLICES):\n",
    "                        start_sample = SAMPLES_PER_SLICE * s\n",
    "                        end_sample = start_sample + SAMPLES_PER_SLICE\n",
    "\n",
    "                        slice_song = song[start_sample:end_sample]\n",
    "\n",
    "                        # Compute STFT\n",
    "                        stft = librosa.stft(slice_song, n_fft=2048, hop_length=512)\n",
    "                        stft_magnitude = librosa.amplitude_to_db(abs(stft))\n",
    "                        stft_magnitude = stft_magnitude.T\n",
    "\n",
    "                        # Serialize example and write to TFRecord file\n",
    "                        label = i - 1  # Adjust label indexing if necessary\n",
    "                        example = serialize_example(stft_magnitude, label)\n",
    "                        writer.write(example)\n",
    "                else:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_MFCC(json_path):\n",
    "    # Load the JSON data from the file\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    x = np.array(data[\"mfcc\"])\n",
    "    y = np.array(data[\"labels\"])\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_STFT(json_path):\n",
    "    # Load the JSON data from the file\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    x = np.array(data[\"stft\"])\n",
    "    y = np.array(data[\"labels\"])\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets(inputs, targets, split_size):\n",
    "    \n",
    "    # Creating a validation set and a test set.\n",
    "    inputs_train, inputs_val, targets_train, targets_val = train_test_split(inputs, targets, test_size=split_size)\n",
    "    inputs_train, inputs_test, targets_train, targets_test = train_test_split(inputs_train, targets_train, test_size=split_size)\n",
    "    \n",
    "    # Our CNN model expects 3D input shape.\n",
    "    inputs_train = inputs_train[..., np.newaxis]\n",
    "    inputs_val = inputs_val[..., np.newaxis]\n",
    "    inputs_test = inputs_test[..., np.newaxis]\n",
    "    \n",
    "    return inputs_train, inputs_val, inputs_test, targets_train, targets_val, targets_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def design_model(input_shape):\n",
    "\n",
    "    # Define the first input\n",
    "    input_1 = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Branch 1\n",
    "    x1 = tf.keras.layers.Conv2D(20, (16, 16), activation='relu')(input_1)\n",
    "    x1 = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x1)\n",
    "    x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "    \n",
    "    x1 = tf.keras.layers.Conv2D(22, (13, 13), activation='relu', padding='same')(x1)\n",
    "    x1 = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x1)\n",
    "    x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "    \n",
    "    x1 = tf.keras.layers.Conv2D(26, (8, 8), activation='relu', padding='same')(x1)\n",
    "    x1 = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x1)\n",
    "    x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "    \n",
    "    x1 = tf.keras.layers.Conv2D(38, (7, 7), activation='relu', padding='same')(x1)\n",
    "    x1 = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x1)\n",
    "    x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "    \n",
    "    x1 = tf.keras.layers.Conv2D(39, (4, 4), activation='relu', padding='same')(x1)\n",
    "    x1 = tf.keras.layers.AveragePooling2D((2, 2), padding='same')(x1)\n",
    "    x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "    x1 = tf.keras.layers.Dropout(0.4)(x1)\n",
    "    \n",
    "    x1 = tf.keras.layers.Flatten()(x1)\n",
    "    x1 = tf.keras.layers.Dense(200, activation='relu')(x1)\n",
    "\n",
    "    # Define the second input\n",
    "    input_2 = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Branch 2\n",
    "    x2 = tf.keras.layers.Conv2D(31, (15, 15), activation='relu')(input_2)\n",
    "    x2 = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x2)\n",
    "    x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "    \n",
    "    x2 = tf.keras.layers.Conv2D(38, (11, 11), activation='relu', padding='same')(x2)\n",
    "    x2 = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x2)\n",
    "    x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "    \n",
    "    x2 = tf.keras.layers.Conv2D(43, (9, 9), activation='relu', padding='same')(x2)\n",
    "    x2 = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x2)\n",
    "    x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "    \n",
    "    x2 = tf.keras.layers.Conv2D(57, (6, 6), activation='relu', padding='same')(x2)\n",
    "    x2 = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x2)\n",
    "    x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "    \n",
    "    x2 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x2)\n",
    "    x2 = tf.keras.layers.AveragePooling2D((2, 2), padding='same')(x2)\n",
    "    x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "    x2 = tf.keras.layers.Dropout(0.4)(x2)\n",
    "    \n",
    "    x2 = tf.keras.layers.Flatten()(x2)\n",
    "    x2 = tf.keras.layers.Dense(200, activation='relu')(x2)\n",
    "\n",
    "    # Concatenate the two branches\n",
    "    merged = tf.keras.layers.Concatenate()([x1, x2])\n",
    "\n",
    "    # Final output layer\n",
    "    output = tf.keras.layers.Dense(10, activation='softmax')(merged)\n",
    "\n",
    "    # Create the model\n",
    "    model = tf.keras.models.Model(inputs=[input_1, input_2], outputs=output)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def design_model(input_shape):\n",
    "\n",
    "    # Let's design the model architecture.\n",
    "    x1 = tf.keras.models.Sequential([\n",
    "\n",
    "        tf.keras.layers.Conv2D(20, (16, 16), activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2), padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(22, (13, 13), activation='relu',padding='same'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2), padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "        tf.keras.layers.Conv2D(26, (8, 8), activation='relu',padding='same'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2), padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "        tf.keras.layers.Conv2D(38, (7, 7), activation='relu',padding='same'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2),  padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "        tf.keras.layers.Conv2D(39, (4, 4), activation='relu',padding='same'),\n",
    "        tf.keras.layers.AveragePooling2D((2, 2), padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.4),\n",
    "        \n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(200, activation='relu'), \n",
    "    ])\n",
    "\n",
    "    return x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(model, X, y, idx):\n",
    "    \n",
    "    genre_dict = {\n",
    "        0 : \"blues\",\n",
    "        1 : \"classical\",\n",
    "        2 : \"country\",\n",
    "        3 : \"disco\",\n",
    "        4 : \"hiphop\",\n",
    "        5 : \"jazz\",\n",
    "        6 : \"metal\",\n",
    "        7 : \"pop\",\n",
    "        8 : \"reggae\",\n",
    "        9 : \"rock\",\n",
    "        }\n",
    "        \n",
    "    predictions = model.predict(X)\n",
    "    genre = np.argmax(predictions[idx])\n",
    "    \n",
    "    print(\"\\n---Now testing the model for one audio file---\\nThe model predicts: {}, and ground truth is: {}.\\n\".format(genre_dict[genre], genre_dict[y[idx]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(hist):\n",
    "    \n",
    "    acc = hist.history['acc']\n",
    "    val_acc = hist.history['val_acc']\n",
    "    loss = hist.history['loss']\n",
    "    val_loss = hist.history['val_loss']\n",
    "\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs, loss, 'r', label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_history(hist):\n",
    "    plt.figure(figsize=(20,15))\n",
    "    fig, axs = plt.subplots(2)\n",
    "    # accuracy subplot\n",
    "    axs[0].plot(hist.history[\"acc\"], label=\"train accuracy\")\n",
    "    axs[0].plot(hist.history[\"val_acc\"], label=\"test accuracy\")    \n",
    "    axs[0].set_ylabel(\"Accuracy\")\n",
    "    axs[0].legend(loc=\"lower right\")\n",
    "    axs[0].set_title(\"Accuracy eval\")\n",
    "    \n",
    "    # Error subplot\n",
    "    axs[1].plot(hist.history[\"loss\"], label=\"train error\")\n",
    "    axs[1].plot(hist.history[\"val_loss\"], label=\"test error\")    \n",
    "    axs[1].set_ylabel(\"Error\")\n",
    "    axs[1].set_xlabel(\"Epoch\")\n",
    "    axs[1].legend(loc=\"upper right\")\n",
    "    axs[1].set_title(\"Error eval\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1727281060.856230    1800 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-25 10:17:41.017376: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpreprocess_data_MFCC\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgenres_original\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtfrecord_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmfcc.tfrecord\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 32\u001b[0m, in \u001b[0;36mpreprocess_data_MFCC\u001b[0;34m(source_path, tfrecord_path)\u001b[0m\n\u001b[1;32m     29\u001b[0m slice_song \u001b[38;5;241m=\u001b[39m song[start_sample:end_sample]\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Compute MFCC\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m mfcc \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmfcc\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslice_song\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_mfcc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m mfcc \u001b[38;5;241m=\u001b[39m mfcc\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Serialize example and write to TFRecord file\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/musica/lib/python3.12/site-packages/librosa/feature/spectral.py:1989\u001b[0m, in \u001b[0;36mmfcc\u001b[0;34m(y, sr, S, n_mfcc, dct_type, norm, lifter, **kwargs)\u001b[0m\n\u001b[1;32m   1843\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Mel-frequency cepstral coefficients (MFCCs)\u001b[39;00m\n\u001b[1;32m   1844\u001b[0m \n\u001b[1;32m   1845\u001b[0m \u001b[38;5;124;03m.. warning:: If multi-channel audio input ``y`` is provided, the MFCC\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1985\u001b[0m \u001b[38;5;124;03m>>> fig.colorbar(img2, ax=[ax[1]])\u001b[39;00m\n\u001b[1;32m   1986\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m S \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1988\u001b[0m     \u001b[38;5;66;03m# multichannel behavior may be different due to relative noise floor differences between channels\u001b[39;00m\n\u001b[0;32m-> 1989\u001b[0m     S \u001b[38;5;241m=\u001b[39m power_to_db(\u001b[43mmelspectrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1991\u001b[0m M: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39mfftpack\u001b[38;5;241m.\u001b[39mdct(S, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mdct_type, norm\u001b[38;5;241m=\u001b[39mnorm)[\n\u001b[1;32m   1992\u001b[0m     \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :n_mfcc, :\n\u001b[1;32m   1993\u001b[0m ]\n\u001b[1;32m   1995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lifter \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1996\u001b[0m     \u001b[38;5;66;03m# shape lifter for broadcasting\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/musica/lib/python3.12/site-packages/librosa/feature/spectral.py:2145\u001b[0m, in \u001b[0;36mmelspectrogram\u001b[0;34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[0m\n\u001b[1;32m   2142\u001b[0m \u001b[38;5;66;03m# Build a Mel filter\u001b[39;00m\n\u001b[1;32m   2143\u001b[0m mel_basis \u001b[38;5;241m=\u001b[39m filters\u001b[38;5;241m.\u001b[39mmel(sr\u001b[38;5;241m=\u001b[39msr, n_fft\u001b[38;5;241m=\u001b[39mn_fft, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 2145\u001b[0m melspec: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m...ft,mf->...mt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmel_basis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m melspec\n",
      "File \u001b[0;32m~/miniconda3/envs/musica/lib/python3.12/site-packages/numpy/core/einsumfunc.py:1419\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(out, optimize, *operands, **kwargs)\u001b[0m\n\u001b[1;32m   1416\u001b[0m     right_pos\u001b[38;5;241m.\u001b[39mappend(input_right\u001b[38;5;241m.\u001b[39mfind(s))\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;66;03m# Contract!\u001b[39;00m\n\u001b[0;32m-> 1419\u001b[0m new_view \u001b[38;5;241m=\u001b[39m \u001b[43mtensordot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtmp_operands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mleft_pos\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mright_pos\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;66;03m# Build a new view if needed\u001b[39;00m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (tensor_result \u001b[38;5;241m!=\u001b[39m results_index) \u001b[38;5;129;01mor\u001b[39;00m handle_out:\n",
      "File \u001b[0;32m~/miniconda3/envs/musica/lib/python3.12/site-packages/numpy/core/numeric.py:1121\u001b[0m, in \u001b[0;36mtensordot\u001b[0;34m(a, b, axes)\u001b[0m\n\u001b[1;32m   1119\u001b[0m at \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mtranspose(newaxes_a)\u001b[38;5;241m.\u001b[39mreshape(newshape_a)\n\u001b[1;32m   1120\u001b[0m bt \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mtranspose(newaxes_b)\u001b[38;5;241m.\u001b[39mreshape(newshape_b)\n\u001b[0;32m-> 1121\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39mreshape(olda \u001b[38;5;241m+\u001b[39m oldb)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "preprocess_data_MFCC(source_path=\"genres_original\", tfrecord_path=\"mfcc.tfrecord\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_data_STFT(source_path=\"genres_original\", tfrecord_path=\"stft.tfrecord\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STFT: [[[ 14.802731    14.823547    17.585005   ... -24.201668   -24.221752\n",
      "   -24.237051  ]\n",
      "  [  5.893271     7.070983     3.1723175  ... -30.234993   -30.245562\n",
      "   -30.344965  ]\n",
      "  [-39.340614   -21.47533      7.953444   ... -39.75795    -39.75795\n",
      "   -39.75795   ]\n",
      "  ...\n",
      "  [-29.203302   -16.962463    -9.829614   ... -39.75795    -39.75795\n",
      "   -39.75795   ]\n",
      "  [-39.419315   -24.786474   -35.671097   ... -39.75795    -39.75795\n",
      "   -39.75795   ]\n",
      "  [-20.615211   -26.535805   -14.911647   ... -39.75795    -39.75795\n",
      "   -39.75795   ]]\n",
      "\n",
      " [[-20.596478   -12.092114     1.0525944  ... -41.2703     -41.2703\n",
      "   -41.2703    ]\n",
      "  [-23.937958   -17.40458      2.8702223  ... -41.2703     -41.2703\n",
      "   -41.2703    ]\n",
      "  [-41.2703     -16.770346     3.8446593  ... -41.2703     -41.2703\n",
      "   -41.2703    ]\n",
      "  ...\n",
      "  [-40.61619    -40.331684   -37.865555   ... -41.2703     -41.2703\n",
      "   -41.2703    ]\n",
      "  [-36.025414   -39.69497    -39.904434   ... -41.2703     -41.2703\n",
      "   -41.2703    ]\n",
      "  [-13.753759   -14.458856   -16.126299   ... -36.04814    -35.811\n",
      "   -35.72879   ]]\n",
      "\n",
      " [[  5.6283092    9.970071    15.139829   ... -25.067633   -23.618937\n",
      "   -23.190605  ]\n",
      "  [ 13.713431    10.18599      8.907737   ... -27.744102   -28.708284\n",
      "   -25.702679  ]\n",
      "  [ 13.313031     7.3408527    5.274134   ... -31.164345   -32.36254\n",
      "   -28.688211  ]\n",
      "  ...\n",
      "  [ 11.909804     7.981985     5.263576   ... -31.24213    -28.091045\n",
      "   -27.712744  ]\n",
      "  [ 11.224037     2.7102785    7.045343   ... -38.442284   -35.269352\n",
      "   -40.28683   ]\n",
      "  [ 13.397028     6.8404827    5.555953   ... -35.704956   -33.74514\n",
      "   -40.28683   ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  5.2528214    4.9195404    5.4531326  ...  -9.120983   -11.690432\n",
      "   -20.000456  ]\n",
      "  [ -2.271686    -1.2798815   -5.9077063  ...  -4.360716    -8.116642\n",
      "   -18.392637  ]\n",
      "  [-31.427536   -10.293692    -3.5064836  ...  -4.7142673   -6.4224577\n",
      "   -16.495256  ]\n",
      "  ...\n",
      "  [ -9.605256    -7.6373043   -9.627832   ...  -8.626866    -6.614703\n",
      "    -5.796916  ]\n",
      "  [ -5.659971    -9.904106   -27.084309   ... -14.92692     -8.846778\n",
      "   -11.550178  ]\n",
      "  [-39.221966    -8.153379   -10.933369   ... -16.974636   -17.275667\n",
      "   -19.673985  ]]\n",
      "\n",
      " [[  7.098746     9.296402    12.216044   ... -17.510004   -18.518959\n",
      "   -23.296804  ]\n",
      "  [ -0.11820499  13.377715    11.035404   ... -15.4797945  -14.733996\n",
      "   -14.063163  ]\n",
      "  [ 19.6086      17.229387     9.23778    ... -24.422743   -20.057678\n",
      "   -17.833607  ]\n",
      "  ...\n",
      "  [ 32.007027    30.248257    21.49908    ... -30.317398   -30.317398\n",
      "   -30.317398  ]\n",
      "  [ 16.285107    28.887146    21.9819     ... -30.317398   -30.317398\n",
      "   -30.317398  ]\n",
      "  [ 31.53151     29.91585     18.237795   ... -22.158024   -28.024014\n",
      "   -27.168709  ]]\n",
      "\n",
      " [[ 21.905293    21.24544     21.387701   ... -19.427498   -19.440058\n",
      "   -19.441864  ]\n",
      "  [ 19.62721     13.57092     12.35853    ... -25.429497   -25.52018\n",
      "   -25.448076  ]\n",
      "  [ 14.084392     8.929353     4.2185097  ... -35.69345    -35.69345\n",
      "   -35.69345   ]\n",
      "  ...\n",
      "  [ 15.231255    10.130645    -0.80517817 ... -35.69345    -35.69345\n",
      "   -35.69345   ]\n",
      "  [ 14.744855     8.709499   -15.041393   ... -35.69345    -35.69345\n",
      "   -35.69345   ]\n",
      "  [ 11.773632     8.012242    -5.2937813  ... -35.69345    -35.69345\n",
      "   -35.69345   ]]]\n",
      "Label: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "STFT shape: (32, 125, 1025)\n"
     ]
    }
   ],
   "source": [
    "feature_description = {\n",
    "    'stft': tf.io.FixedLenFeature([], tf.string),\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "}\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "    parsed_example = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    stft = tf.io.parse_tensor(parsed_example['stft'], out_type=tf.float32)\n",
    "    label = parsed_example['label']\n",
    "    return stft, label\n",
    "\n",
    "def create_dataset(tfrecord_path, batch_size=32, shuffle_buffer_size=1000):\n",
    "    raw_dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "    parsed_dataset = raw_dataset.map(_parse_function)\n",
    "    dataset = parsed_dataset.shuffle(shuffle_buffer_size).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "stft_data = create_dataset('stft.tfrecord')\n",
    "\n",
    "# Example of data from the dataset\n",
    "for stft, label in stft_data.take(1):\n",
    "    print(\"STFT:\", stft.numpy())\n",
    "    print(\"Label:\", label.numpy())\n",
    "    print(\"STFT shape:\", stft.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature description to parse TFRecord files\n",
    "feature_description = {\n",
    "    'mfcc': tf.io.FixedLenFeature([], tf.string),\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "}\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "    parsed_example = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    mfcc = tf.io.parse_tensor(parsed_example['mfcc'], out_type=tf.float32)\n",
    "    label = parsed_example['label']\n",
    "    return mfcc, label\n",
    "\n",
    "def create_dataset(tfrecord_path, batch_size=32, shuffle_buffer_size=1000):\n",
    "    raw_dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "    parsed_dataset = raw_dataset.map(_parse_function)\n",
    "    dataset = parsed_dataset.shuffle(shuffle_buffer_size).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "def split_dataset(dataset, split_ratio=0.8):\n",
    "    dataset_size = len(list(dataset))  # Note: This approach is memory-intensive for large datasets\n",
    "    train_size = int(dataset_size * split_ratio)\n",
    "    test_size = dataset_size - train_size\n",
    "    \n",
    "    train_dataset = dataset.take(train_size)\n",
    "    test_dataset = dataset.skip(train_size).take(test_size)\n",
    "    \n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "mfcc_data = create_dataset('mfcc.tfrecord')\n",
    "\n",
    "mfcc_train, mfcc_test = split_dataset(mfcc_data)\n",
    "\n",
    "for mfcc, label in mfcc_train.take(1):\n",
    "    mfcc_shape=mfcc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nai/miniconda3/envs/musica/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "input_shape = (mfcc_shape[1], mfcc_shape[2], 1)\n",
    "model = design_model(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0025),\n",
    "                     loss='sparse_categorical_crossentropy',\n",
    "                     metrics = ['acc']\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">113</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,140</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_15          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">74,382</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_16          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">88</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,634</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_17          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">48,450</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_18          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">23,751</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_19          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">624</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">125,000</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m, \u001b[38;5;34m113\u001b[0m, \u001b[38;5;34m20\u001b[0m)   │         \u001b[38;5;34m5,140\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_12 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m57\u001b[0m, \u001b[38;5;34m20\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_15          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m57\u001b[0m, \u001b[38;5;34m20\u001b[0m)     │            \u001b[38;5;34m80\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m57\u001b[0m, \u001b[38;5;34m22\u001b[0m)     │        \u001b[38;5;34m74,382\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_13 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m22\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_16          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m22\u001b[0m)     │            \u001b[38;5;34m88\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m26\u001b[0m)     │        \u001b[38;5;34m36,634\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_14 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m26\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_17          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m26\u001b[0m)     │           \u001b[38;5;34m104\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m38\u001b[0m)     │        \u001b[38;5;34m48,450\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_15 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m38\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_18          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m38\u001b[0m)       │           \u001b[38;5;34m152\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m39\u001b[0m)       │        \u001b[38;5;34m23,751\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m39\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_19          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m39\u001b[0m)       │           \u001b[38;5;34m156\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m39\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m624\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │       \u001b[38;5;34m125,000\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">313,937</span> (1.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m313,937\u001b[0m (1.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">313,647</span> (1.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m313,647\u001b[0m (1.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">290</span> (1.13 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m290\u001b[0m (1.13 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(dataset):\n",
    "    dataset = dataset.shuffle(1000).batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "mfcc_train = prepare_dataset(mfcc_train)\n",
    "mfcc_test = prepare_dataset(mfcc_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mCannot take the length of shape with unknown rank.\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=<unknown>, dtype=float32)\n  • training=True\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[138], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmfcc_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmfcc_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m75\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/musica/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/musica/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mCannot take the length of shape with unknown rank.\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=<unknown>, dtype=float32)\n  • training=True\n  • mask=None"
     ]
    }
   ],
   "source": [
    "history = model.fit(mfcc_train,\n",
    "                    validation_data=mfcc_test,\n",
    "                    epochs=75\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during model call: Exception encountered when calling Sequential.call().\n",
      "\n",
      "\u001b[1mInput 0 of layer \"conv2d_15\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (32, 32, 125, 128)\u001b[0m\n",
      "\n",
      "Arguments received by Sequential.call():\n",
      "  • inputs=tf.Tensor(shape=(32, 32, 125, 128), dtype=float32)\n",
      "  • training=None\n",
      "  • mask=None\n"
     ]
    }
   ],
   "source": [
    "sample_batch = next(iter(mfcc_train))\n",
    "try:\n",
    "    model(sample_batch[0])  # Pass a batch of features through the model\n",
    "except Exception as e:\n",
    "    print(\"Error during model call:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_performance(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = history.history['acc'][-1]  # Last epoch accuracy\n",
    "test_accuracy = history.history['val_acc'][-1]  # Last epoch validation accuracy\n",
    "\n",
    "# Print accuracies\n",
    "print('Training accuracy:', train_accuracy)\n",
    "print('Test accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_prediction(model, Xtest_MFCC, ytest_MFCC, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a file\n",
    "with open('CNN.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
