{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-10 10:15:44.474373: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-10 10:15:44.484462: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-10 10:15:44.487588: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-10 10:15:44.495744: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-10 10:15:45.053034: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 22050\n",
    "TOTAL_SAMPLES = 29 * sr\n",
    "\n",
    "NUM_SLICES = 10\n",
    "SAMPLES_PER_SLICE = int(TOTAL_SAMPLES / NUM_SLICES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_audio(slice_song, sr):\n",
    "    # Time stretching\n",
    "    stretch_rate = np.random.uniform(0.8, 1.2)\n",
    "    slice_song_stretched = librosa.effects.time_stretch(slice_song,rate=stretch_rate)\n",
    "\n",
    "    # Pitch shifting\n",
    "    pitch_shift = np.random.randint(-2, 3)  # Shift between -2 and +2 semitones\n",
    "    slice_song_pitched = librosa.effects.pitch_shift(slice_song_stretched, sr=sr, n_steps=pitch_shift)\n",
    "\n",
    "    # Adding noise\n",
    "    noise_factor = 0.005\n",
    "    noise = np.random.randn(len(slice_song_pitched))\n",
    "    slice_song_noisy = slice_song_pitched + noise_factor * noise\n",
    "\n",
    "    # Random volume adjustment\n",
    "    volume_factor = np.random.uniform(0.5, 1.5)\n",
    "    slice_song_augmented = slice_song_noisy * volume_factor\n",
    "\n",
    "    return slice_song_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_MFCC(source_path, json_path):\n",
    "\n",
    "    # Dictionary of labels and processed data.\n",
    "    mydict = {\n",
    "        \"labels\": [],\n",
    "        \"mfcc\": []\n",
    "        }\n",
    "\n",
    "    # Browse each file, slice it and generate the 128 band mfcc for each slice.\n",
    "    for i, (dirpath,dirname, filenames) in enumerate(os.walk(source_path)):\n",
    "        for file in filenames:\n",
    "            # exclude a corrupted wav file that makes everything crash.\n",
    "            if os.path.join(dirpath, file) != 'genres_original/jazz/jazz.00054.wav':\n",
    "                song, sr = librosa.load(os.path.join(dirpath, file), duration=29)\n",
    "                for s in range(NUM_SLICES):\n",
    "                    start_sample = SAMPLES_PER_SLICE * s\n",
    "                    end_sample = start_sample + SAMPLES_PER_SLICE\n",
    "\n",
    "                    slice_song=song[start_sample:end_sample]\n",
    "\n",
    "                    #augmented_slice=augment_audio(slice_song,sr)\n",
    "\n",
    "                    # Compute MFCC\n",
    "                    mfcc = librosa.feature.mfcc(y=slice_song, sr=sr, n_mfcc=128)\n",
    "                    mfcc = mfcc.T\n",
    "\n",
    "                    mydict[\"labels\"].append(i-1)\n",
    "                    mydict[\"mfcc\"].append(mfcc.tolist())\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    # Write the dictionary in a json file.    \n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(mydict, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_STFT(source_path, json_path):\n",
    "\n",
    "    # Dictionary of labels and processed data.\n",
    "    mydict = {\n",
    "        \"labels\": [],\n",
    "        \"stft\": [] \n",
    "        }\n",
    "\n",
    "    # Browse each file, slice it and generate the 128 band mfcc for each slice.\n",
    "    for i, (dirpath,dirname, filenames) in enumerate(os.walk(source_path)):\n",
    "        for file in filenames:\n",
    "            # exclude a corrupted wav file that makes everything crash.\n",
    "            if os.path.join(dirpath, file) != 'genres_original/jazz/jazz.00054.wav':\n",
    "                song, sr = librosa.load(os.path.join(dirpath, file), duration=29)\n",
    "                for s in range(NUM_SLICES):\n",
    "                    start_sample = SAMPLES_PER_SLICE * s\n",
    "                    end_sample = start_sample + SAMPLES_PER_SLICE\n",
    "\n",
    "                    slice_song=song[start_sample:end_sample]\n",
    "\n",
    "                    #augmented_slice=augment_audio(slice_song,sr)\n",
    "\n",
    "                    # Compute STFT\n",
    "                    stft = np.abs(librosa.stft(slice_song,n_fft=256,hop_length=512))\n",
    "                    stft = stft.T\n",
    "\n",
    "                    mydict[\"labels\"].append(i-1)\n",
    "                    mydict[\"stft\"].append(stft.tolist())\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    # Write the dictionary in a json file.    \n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(mydict, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_MFCC(json_path):\n",
    "    # Load the JSON data from the file\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    x = np.array(data[\"mfcc\"])\n",
    "    y = np.array(data[\"labels\"])\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_STFT(json_path):\n",
    "    # Load the JSON data from the file\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    x = np.array(data[\"stft\"])\n",
    "    y = np.array(data[\"labels\"])\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets(inputs, targets, split_size):\n",
    "    \n",
    "    # Creating a validation set and a test set.\n",
    "    inputs_train, inputs_val, targets_train, targets_val = train_test_split(inputs, targets, test_size=split_size)\n",
    "    inputs_train, inputs_test, targets_train, targets_test = train_test_split(inputs_train, targets_train, test_size=split_size)\n",
    "    \n",
    "    # Our CNN model expects 3D input shape.\n",
    "    inputs_train = inputs_train[..., np.newaxis]\n",
    "    inputs_val = inputs_val[..., np.newaxis]\n",
    "    inputs_test = inputs_test[..., np.newaxis]\n",
    "    \n",
    "    return inputs_train, inputs_val, inputs_test, targets_train, targets_val, targets_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def design_model(input_shape_MFCC, input_shape_STFT):\n",
    "\n",
    "    # Define the MFCC branch (x1)\n",
    "    input_MFCC = tf.keras.Input(shape=input_shape_MFCC)\n",
    "    x1 = tf.keras.layers.Conv2D(20, (16, 16), activation='relu')(input_MFCC)\n",
    "    x1 = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x1)\n",
    "    x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "    \n",
    "    x1 = tf.keras.layers.Conv2D(22, (13, 13), activation='relu', padding='same')(x1)\n",
    "    x1 = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x1)\n",
    "    x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "    \n",
    "    x1 = tf.keras.layers.Conv2D(26, (8, 8), activation='relu', padding='same')(x1)\n",
    "    x1 = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x1)\n",
    "    x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "\n",
    "    x1 = tf.keras.layers.Conv2D(38, (7, 7), activation='relu', padding='same')(x1)\n",
    "    x1 = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x1)\n",
    "    x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "\n",
    "    x1 = tf.keras.layers.Conv2D(39, (4, 4), activation='relu', padding='same')(x1)\n",
    "    x1 = tf.keras.layers.AveragePooling2D((2, 2), padding='same')(x1)\n",
    "    x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "    x1 = tf.keras.layers.Dropout(0.4)(x1)\n",
    "    \n",
    "    x1 = tf.keras.layers.Flatten()(x1)\n",
    "    x1 = tf.keras.layers.Dense(200, activation='relu')(x1)\n",
    "    \n",
    "    # Define the STFT branch (x2)\n",
    "    input_STFT = tf.keras.Input(shape=input_shape_STFT)\n",
    "    x2 = tf.keras.layers.Conv2D(31, (15, 15), activation='relu')(input_STFT)\n",
    "    x2 = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x2)\n",
    "    x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "    \n",
    "    x2 = tf.keras.layers.Conv2D(38, (11, 11), activation='relu', padding='same')(x2)\n",
    "    x2 = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x2)\n",
    "    x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "    \n",
    "    x2 = tf.keras.layers.Conv2D(43, (9, 9), activation='relu', padding='same')(x2)\n",
    "    x2 = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x2)\n",
    "    x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "\n",
    "    x2 = tf.keras.layers.Conv2D(57, (6, 6), activation='relu', padding='same')(x2)\n",
    "    x2 = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x2)\n",
    "    x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "\n",
    "    x2 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x2)\n",
    "    x2 = tf.keras.layers.AveragePooling2D((2, 2), padding='same')(x2)\n",
    "    x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "    x2 = tf.keras.layers.Dropout(0.4)(x2)\n",
    "    \n",
    "    x2 = tf.keras.layers.Flatten()(x2)\n",
    "    x2 = tf.keras.layers.Dense(200, activation='relu')(x2)\n",
    "\n",
    "    # Concatenate both branches\n",
    "    merged = tf.keras.layers.Concatenate()([x1, x2])\n",
    "\n",
    "    # Output layer\n",
    "    output = tf.keras.layers.Dense(10, activation='softmax')(merged)\n",
    "\n",
    "    # Create the model\n",
    "    model = tf.keras.Model(inputs=[input_MFCC, input_STFT], outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(model, X, y, idx):\n",
    "    \n",
    "    genre_dict = {\n",
    "        0 : \"blues\",\n",
    "        1 : \"classical\",\n",
    "        2 : \"country\",\n",
    "        3 : \"disco\",\n",
    "        4 : \"hiphop\",\n",
    "        5 : \"jazz\",\n",
    "        6 : \"metal\",\n",
    "        7 : \"pop\",\n",
    "        8 : \"reggae\",\n",
    "        9 : \"rock\",\n",
    "        }\n",
    "        \n",
    "    predictions = model.predict(X)\n",
    "    genre = np.argmax(predictions[idx])\n",
    "    \n",
    "    print(\"\\n---Now testing the model for one audio file---\\nThe model predicts: {}, and ground truth is: {}.\\n\".format(genre_dict[genre], genre_dict[y[idx]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(hist):\n",
    "    \n",
    "    acc = hist.history['acc']\n",
    "    val_acc = hist.history['val_acc']\n",
    "    loss = hist.history['loss']\n",
    "    val_loss = hist.history['val_loss']\n",
    "\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs, loss, 'r', label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_history(hist):\n",
    "    plt.figure(figsize=(20,15))\n",
    "    fig, axs = plt.subplots(2)\n",
    "    # accuracy subplot\n",
    "    axs[0].plot(hist.history[\"acc\"], label=\"train accuracy\")\n",
    "    axs[0].plot(hist.history[\"val_acc\"], label=\"test accuracy\")    \n",
    "    axs[0].set_ylabel(\"Accuracy\")\n",
    "    axs[0].legend(loc=\"lower right\")\n",
    "    axs[0].set_title(\"Accuracy eval\")\n",
    "    \n",
    "    # Error subplot\n",
    "    axs[1].plot(hist.history[\"loss\"], label=\"train error\")\n",
    "    axs[1].plot(hist.history[\"val_loss\"], label=\"test error\")    \n",
    "    axs[1].set_ylabel(\"Error\")\n",
    "    axs[1].set_xlabel(\"Epoch\")\n",
    "    axs[1].legend(loc=\"upper right\")\n",
    "    axs[1].set_title(\"Error eval\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"mfcc.json\"):\n",
    "    preprocess_data_MFCC(source_path=\"genres_original\", json_path=\"mfcc.json\")\n",
    "else:\n",
    "    print(\"File already exists, skipping preprocessing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"stft.json\"):\n",
    "    preprocess_data_STFT(source_path=\"genres_original\", json_path=\"stft.json\")\n",
    "else:\n",
    "    print(\"File already exists, skipping preprocessing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_MFCC, targets_MFCC = load_data_MFCC(json_path=\"mfcc.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_MFCC.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_STFT, targets_STFT= load_data_STFT(json_path=\"stft.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_STFT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "librosa.display.specshow(librosa.amplitude_to_db(inputs_STFT[0],ref=np.max),y_axis=\"log\",x_axis=\"time\",ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use either targets_STFT or targets_MFCC as the labels (they should be the same)\n",
    "y = targets_STFT  # Assuming both target arrays are identical\n",
    "\n",
    "# Ensure the labels are one-hot encoded for classification\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_onehot = label_binarizer.fit_transform(y)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "inputs_MFCC_train, inputs_MFCC_val, inputs_STFT_train, inputs_STFT_val, y_train, y_val = train_test_split(\n",
    "    inputs_MFCC, inputs_STFT, y_onehot, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create the model\n",
    "input_shape_MFCC = (inputs_MFCC_train.shape[1],inputs_MFCC_train.shape[2],1)  # Shape of MFCC input\n",
    "input_shape_STFT = (inputs_STFT_train.shape[1],inputs_STFT_train.shape[2],1)  # Shape of STFT input\n",
    "model = design_model(input_shape_MFCC, input_shape_STFT)\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0025),\n",
    "                     loss='categorical_crossentropy',\n",
    "                     metrics = ['acc']\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    [inputs_MFCC_train, inputs_STFT_train],  # The two inputs for the model\n",
    "    y_train,  # The target labels\n",
    "    validation_data=([inputs_MFCC_val, inputs_STFT_val], y_val),\n",
    "    epochs=30,\n",
    "    batch_size=32\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_performance(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = history.history['acc'][-1]  # Last epoch accuracy\n",
    "test_accuracy = history.history['val_acc'][-1]  # Last epoch validation accuracy\n",
    "\n",
    "# Print accuracies\n",
    "print('Training accuracy:', train_accuracy)\n",
    "print('Test accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a file\n",
    "with open('CNN9.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
